{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import numpy as np\n",
    "import os\n",
    "from pydrake.all import (StartMeshcat, MeshcatVisualizer, DiagramBuilder, Parser, ConstantVectorSource,\n",
    "                        Simulator, LeafSystem, RigidTransform, RotationMatrix, ProcessModelDirectives,\n",
    "                        UniformlyRandomRotationMatrix, RandomGenerator, Rgba, LoadModelDirectivesFromString,\n",
    "                        PiecewisePose, TrajectorySource, Integrator, JacobianWrtVariable, AbstractValue, \n",
    "                        PointCloud, ImageRgba8U, ImageDepth32F, Concatenate, AddMultibodyPlantSceneGraph, \n",
    "                        MeshcatVisualizerParams, Role, RollPitchYaw, BaseField, Fields)\n",
    "# from manipulation.clutter import GenerateAntipodalGraspCandidate\n",
    "from manipulation.meshcat_utils import AddMeshcatTriad\n",
    "from manipulation import FindResource\n",
    "from manipulation.scenarios import (AddIiwaDifferentialIK, MakeManipulationStation, AddPackagePaths)\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as Tf\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.models.detection import MaskRCNN_ResNet50_FPN_Weights\n",
    "\n",
    "# For diagram viz\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Meshcat listening for connections at http://localhost:7001\n"
     ]
    }
   ],
   "source": [
    "meshcat = StartMeshcat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects randomized successfully after 1 tries\n"
     ]
    }
   ],
   "source": [
    "rs = np.random.RandomState()  # this is for python\n",
    "generator = RandomGenerator(rs.randint(1000)) # this is for c++\n",
    "\n",
    "path = os.getcwd()\n",
    "TRASH_YAML = path + '/models/trash_model.dmd.yaml'\n",
    "INTERNAL_YAML = path + \"/models/internal_model.dmd.yaml\"\n",
    "MODEL_YAML = path + \"/models/recycling.dmd.yaml\"\n",
    "MODEL_PATH = 'recycling_maskrcnn_model.pt'\n",
    "\n",
    "q0 = [-1.57, -0.1, 0, -1.4, 0, 1.6, 0]\n",
    "X_WHome = RigidTransform(\n",
    "            RotationMatrix([\n",
    "                [1, 0, 0],\n",
    "                [0, 0, 1],\n",
    "                [0, -1, 0]\n",
    "            ]),\n",
    "            [0, -0.5, 0.65])\n",
    "\n",
    "ITEM_NAMES = [\"cola_can\", \"bottle\", \"Banana\", \"Orange\", \"coffee\"]\n",
    "\n",
    "get_garbage_type = {\"cola\": GarbageType.RECYCLE, \"bottle\": GarbageType.RECYCLE, \n",
    "                   \"Banana\": GarbageType.ORGANIC, \"Orange\": GarbageType.ORGANIC,\n",
    "                   \"coffee\": GarbageType.TRASH}\n",
    "\n",
    "class GarbageType(Enum):\n",
    "    TRASH = 0\n",
    "    RECYCLE = 1\n",
    "    ORGANIC = 2\n",
    "\n",
    "    \n",
    "# Contains iiwa, bins, table, floor\n",
    "def make_internal_model():\n",
    "    station = MakeManipulationStation(\n",
    "        filename=FindResource(INTERNAL_YAML),\n",
    "        package_xmls=[\"./package.xml\"])\n",
    "    return station\n",
    "\n",
    "\n",
    "# Contains table & trash\n",
    "def make_trash_model():\n",
    "    builder = DiagramBuilder()\n",
    "    plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.001)\n",
    "    parser = Parser(plant)\n",
    "    parser.package_map().AddPackageXml('./package.xml')\n",
    "    AddPackagePaths(parser)\n",
    "    parser.AddAllModelsFromFile(TRASH_YAML)\n",
    "    plant.Finalize()\n",
    "    return builder.Build()\n",
    "    \n",
    "\n",
    "class PseudoInverseController(LeafSystem):\n",
    "    def __init__(self, plant):\n",
    "        LeafSystem.__init__(self)\n",
    "        self._plant = plant\n",
    "        self._plant_context = plant.CreateDefaultContext()\n",
    "        self._iiwa = plant.GetModelInstanceByName(\"iiwa\")\n",
    "        self._G = plant.GetBodyByName(\"body\").body_frame()\n",
    "        self._W = plant.world_frame()\n",
    "\n",
    "        self.V_G_port = self.DeclareVectorInputPort(\"V_WG\", 6)\n",
    "        self.q_port = self.DeclareVectorInputPort(\"iiwa_position\", 7)\n",
    "        self.DeclareVectorOutputPort(\"iiwa_velocity\", 7, self.CalcOutput)\n",
    "        self.iiwa_start = plant.GetJointByName(\"iiwa_joint_1\").velocity_start()\n",
    "        self.iiwa_end = plant.GetJointByName(\"iiwa_joint_7\").velocity_start()\n",
    "\n",
    "    def CalcOutput(self, context, output):\n",
    "        V_G = self.V_G_port.Eval(context)\n",
    "        q = self.q_port.Eval(context)\n",
    "        self._plant.SetPositions(self._plant_context, self._iiwa, q)\n",
    "        J_G = self._plant.CalcJacobianSpatialVelocity(\n",
    "            self._plant_context, JacobianWrtVariable.kV,\n",
    "            self._G, [0,0,0], self._W, self._W)\n",
    "        J_G = J_G[:,self.iiwa_start:self.iiwa_end+1] # Only iiwa terms.\n",
    "        v = np.linalg.pinv(J_G).dot(V_G)\n",
    "        output.SetFromVector(v)\n",
    "        \n",
    "        \n",
    "class Vision(LeafSystem):\n",
    "    def __init__(self, station, camera_body_indices):\n",
    "        LeafSystem.__init__(self)\n",
    "        \n",
    "        rgb_image = AbstractValue.Make(ImageRgba8U(640,480))\n",
    "        depth_image = AbstractValue.Make(ImageDepth32F(640,480))\n",
    "        point_cloud = AbstractValue.Make(PointCloud(0))\n",
    "        self.DeclareAbstractInputPort(\"depth0\", depth_image)\n",
    "        self.DeclareAbstractInputPort(\"depth1\", depth_image)\n",
    "        self.DeclareAbstractInputPort(\"rgb0\", rgb_image)\n",
    "        self.DeclareAbstractInputPort(\"rgb1\", rgb_image)\n",
    "        self.DeclareAbstractInputPort(\n",
    "            \"body_poses\", AbstractValue.Make([RigidTransform()]))\n",
    "        \n",
    "        self.DeclareAbstractOutputPort(\"point_cloud_W\", \n",
    "            lambda: AbstractValue.Make((0, ITEM_NAMES[0], point_cloud)), \n",
    "            self.SendSegmentedCloud)\n",
    "            \n",
    "        # Crop box for area of interest\n",
    "        self._crop_lower = np.array([-.5, -.75, .39])\n",
    "        self._crop_upper = np.array([.5, -.45, .475])\n",
    "        \n",
    "        self._camera_body_indices = camera_body_indices\n",
    "        self.cam_info_0 = station.GetSubsystemByName('camera0').depth_camera_info()\n",
    "        self.cam_info_1 = station.GetSubsystemByName('camera0').depth_camera_info()\n",
    "            \n",
    "        ## Load model\n",
    "        num_classes = len(ITEM_NAMES) + 1\n",
    "        self.model = self.load_model(num_classes)\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.model.load_state_dict(torch.load(MODEL_PATH, map_location=self.device))\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "    def load_model(self, num_classes):\n",
    "        \n",
    "        # load an instance segmentation model pre-trained on COCO\n",
    "        model = torchvision.models.detection.maskrcnn_resnet50_fpn(\n",
    "            weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT, progress=False)\n",
    "\n",
    "        # get the number of input features for the classifier\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        # replace the pre-trained head with a new one\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "        # now get the number of input features for the mask classifier\n",
    "        in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "        hidden_layer = 256\n",
    "        # and replace the mask predictor with a new one\n",
    "        model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "            in_features_mask, hidden_layer, num_classes)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def SendSegmentedCloud(self, context, output):\n",
    "        \n",
    "        body_poses = self.GetInputPort(\"body_poses\").Eval(context)\n",
    "        rgb0 = self.GetInputPort(\"rgb0\").Eval(context).data\n",
    "        rgb1 = self.GetInputPort(\"rgb1\").Eval(context).data\n",
    "        depth0 = self.GetInputPort(\"depth0\").Eval(context).data\n",
    "        depth1 = self.GetInputPort(\"depth1\").Eval(context).data\n",
    "                \n",
    "        # Put through deep model\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            predictions.append(\n",
    "                self.model([Tf.to_tensor(rgb0[:, :, :3]).to(self.device)]))\n",
    "            predictions.append(\n",
    "                self.model([Tf.to_tensor(rgb1[:, :, :3]).to(self.device)]))\n",
    "        for i in range(2):\n",
    "            for k in predictions[i][0].keys():\n",
    "                if k == \"masks\":\n",
    "                    predictions[i][0][k] = predictions[i][0][k].mul(\n",
    "                        255).byte().cpu().numpy()\n",
    "                else:\n",
    "                    predictions[i][0][k] = predictions[i][0][k].cpu().numpy()\n",
    "        \n",
    "        X_WCs = []\n",
    "        for idx in self._camera_body_indices:\n",
    "            X_WCs.append(body_poses[idx])\n",
    "        \n",
    "        score, obj_idx, cloud = self.get_merged_masked_pcd(predictions, [rgb0, rgb1], \n",
    "           [depth0, depth1], [self.project_depth_to_pC, self.project_depth_to_pC], \n",
    "           X_WCs, [self.cam_info_0, self.cam_info_1])\n",
    "        \n",
    "        cloud.Crop(self._crop_lower, self._crop_upper)\n",
    "        \n",
    "        output.set_value((score, ITEM_NAMES[obj_idx], cloud))\n",
    "        \n",
    "    def get_merged_masked_pcd(self, predictions, rgb_ims, depth_ims, \n",
    "          project_depth_to_pC_funcs, X_WCs, cam_infos, mask_threshold=150):\n",
    "        \"\"\"\n",
    "        predictions: The output of the trained network (one for each camera)\n",
    "        rgb_ims: RGBA images from each camera\n",
    "        depth_ims: Depth images from each camera\n",
    "        project_depth_to_pC_funcs: Functions that perform the pinhole camera operations to convert pixels\n",
    "            into points. See the analogous function in problem 5.2 to see how to use it.\n",
    "        X_WCs: Poses of the cameras in the world frame\n",
    "        \"\"\"\n",
    "        # Let's focus on the maximal confidence object\n",
    "        # Limitation: Assumes object uniqueness\n",
    "        scores = {}\n",
    "        for obj_idx in range(len(ITEM_NAMES)):\n",
    "            combined_score = 0\n",
    "            for p in predictions:\n",
    "                if obj_idx not in p[0]['labels']:\n",
    "                    continue\n",
    "                combined_score += np.max(\n",
    "                    p[0]['scores'][p[0]['labels'] == obj_idx])\n",
    "            if combined_score > 0:\n",
    "                scores[obj_idx] = combined_score\n",
    "            \n",
    "        print(scores)\n",
    "        if not bool(scores):\n",
    "            return 0, -1, PointCloud(0)\n",
    "        \n",
    "        obj_idx = max(scores, key=scores.get)\n",
    "        print(\"Decided to pick up \", ITEM_NAMES[obj_idx])\n",
    "        \n",
    "        pcd = []\n",
    "        for prediction, rgb_im, depth_im, project_depth_to_pC_func, X_WC, cam_info in \\\n",
    "                zip(predictions, rgb_ims, depth_ims, project_depth_to_pC_funcs, X_WCs, cam_infos):\n",
    "\n",
    "            obj_masks = prediction[0]['masks'][prediction[0]['labels'] == obj_idx]\n",
    "            mask = obj_masks[0,0]\n",
    "            idx = np.where(mask >= mask_threshold)\n",
    "            depth_pts = np.column_stack((idx[0], idx[1], depth_im[idx[0], idx[1]]))\n",
    "            p_C_obj = project_depth_to_pC_func(depth_pts, cam_info)\n",
    "            spatial_points = X_WC @ p_C_obj.T\n",
    "            rgb_points = rgb_im[idx[0], idx[1], 0:3].T\n",
    "\n",
    "            # You get an unhelpful RunTime error if your arrays are the wrong\n",
    "            # shape, so we'll check beforehand that they're the correct shapes.\n",
    "            assert len(spatial_points.shape\n",
    "                      ) == 2, \"Spatial points is the wrong size -- should be 3 x N\"\n",
    "            assert spatial_points.shape[\n",
    "                0] == 3, \"Spatial points is the wrong size -- should be 3 x N\"\n",
    "            assert len(rgb_points.shape\n",
    "                      ) == 2, \"RGB points is the wrong size -- should be 3 x N\"\n",
    "            assert rgb_points.shape[\n",
    "                0] == 3, \"RGB points is the wrong size -- should be 3 x N\"\n",
    "            assert rgb_points.shape[1] == spatial_points.shape[1]\n",
    "\n",
    "            N = spatial_points.shape[1]\n",
    "            pcd.append(PointCloud(N, Fields(BaseField.kXYZs | BaseField.kRGBs)))\n",
    "            pcd[-1].mutable_xyzs()[:] = spatial_points\n",
    "            pcd[-1].mutable_rgbs()[:] = rgb_points\n",
    "            # Estimate normals\n",
    "            pcd[-1].EstimateNormals(radius=0.1, num_closest=30)\n",
    "            # Flip normals toward camera\n",
    "            pcd[-1].FlipNormalsTowardPoint(X_WC.translation())\n",
    "\n",
    "        # Merge point clouds.\n",
    "        merged_pcd = Concatenate(pcd)\n",
    "        \n",
    "        # Get the prediciton score\n",
    "        avg_score = scores[obj_idx] / len(rgb_ims)\n",
    "\n",
    "        # Voxelize down-sample.  (Note that the normals still look reasonable)\n",
    "        return avg_score, obj_idx, merged_pcd.VoxelizedDownSample(voxel_size=0.005)\n",
    "    \n",
    "    def project_depth_to_pC(self, depth_pixel, cam_info):\n",
    "        \"\"\"\n",
    "        project depth pixels to points in camera frame\n",
    "        using pinhole camera model\n",
    "        Input:\n",
    "            depth_pixels: numpy array of (nx3) or (3,)\n",
    "        Output:\n",
    "            pC: 3D point in camera frame, numpy array of (nx3)\n",
    "        \"\"\"\n",
    "        # switch u,v due to python convention\n",
    "        v = depth_pixel[:,0]\n",
    "        u = depth_pixel[:,1]\n",
    "        Z = depth_pixel[:,2]\n",
    "        cx = cam_info.center_x()\n",
    "        cy = cam_info.center_y()\n",
    "        fx = cam_info.focal_x()\n",
    "        fy = cam_info.focal_y()\n",
    "        X = (u-cx) * Z/fx\n",
    "        Y = (v-cy) * Z/fy\n",
    "        pC = np.c_[X,Y,Z]\n",
    "        return pC\n",
    "        \n",
    "            \n",
    "class GraspSelector(LeafSystem):\n",
    "    def __init__(self):\n",
    "        LeafSystem.__init__(self)\n",
    "        \n",
    "        point_cloud = AbstractValue.Make(PointCloud(0))\n",
    "        self.DeclareAbstractInputPort(\"point_cloud_W\", \n",
    "            AbstractValue.Make((0, ITEM_NAMES[0], point_cloud)))\n",
    "        \n",
    "        port = self.DeclareAbstractOutputPort(\n",
    "            \"grasp_selection\", \n",
    "            lambda: AbstractValue.Make((np.inf, RigidTransform(), ITEM_NAMES[0])), \n",
    "            self.SelectGrasp)\n",
    "        port.disable_caching_by_default()\n",
    "        \n",
    "        self._internal_model = make_internal_model()\n",
    "        self._internal_model_context = self._internal_model.CreateDefaultContext()\n",
    "        self._rng = np.random.default_rng()\n",
    "        self.X_WHome = X_WHome\n",
    "        \n",
    "    # Taken from manipulation/clutter.py - slightly modified\n",
    "    def GraspCandidateCost(self, diagram, context, cloud, wsg_body_index=None, plant_system_name=\"plant\",\n",
    "                           scene_graph_system_name=\"scene_graph\", adjust_X_G=False):\n",
    "        plant = diagram.GetSubsystemByName(plant_system_name)\n",
    "        plant_context = plant.GetMyMutableContextFromRoot(context)\n",
    "        scene_graph = diagram.GetSubsystemByName(scene_graph_system_name)\n",
    "        scene_graph_context = scene_graph.GetMyMutableContextFromRoot(context)\n",
    "        if wsg_body_index:\n",
    "            wsg = plant.get_body(wsg_body_index)\n",
    "        else:\n",
    "            wsg = plant.GetBodyByName(\"body\")\n",
    "            wsg_body_index = wsg.index()\n",
    "\n",
    "        X_G = plant.GetFreeBodyPose(plant_context, wsg)\n",
    "\n",
    "        # Transform cloud into gripper frame\n",
    "        X_GW = X_G.inverse()\n",
    "        p_GC = X_GW @ cloud.xyzs()\n",
    "\n",
    "        # Crop to a region inside of the finger box.\n",
    "        crop_min = [-.05, 0.1, -0.00625]\n",
    "        crop_max = [.05, 0.1125, 0.00625]\n",
    "        indices = np.all((crop_min[0] <= p_GC[0, :], p_GC[0, :] <= crop_max[0],\n",
    "                          crop_min[1] <= p_GC[1, :], p_GC[1, :] <= crop_max[1],\n",
    "                          crop_min[2] <= p_GC[2, :], p_GC[2, :] <= crop_max[2]),\n",
    "                         axis=0)\n",
    "\n",
    "        if adjust_X_G and np.sum(indices) > 0:\n",
    "            p_GC_x = p_GC[0, indices]\n",
    "            p_Gcenter_x = (p_GC_x.min() + p_GC_x.max()) / 2.0\n",
    "            X_G.set_translation(X_G @ np.array([p_Gcenter_x, 0, 0]))\n",
    "            plant.SetFreeBodyPose(plant_context, wsg, X_G)\n",
    "            X_GW = X_G.inverse()\n",
    "\n",
    "        query_object = scene_graph.get_query_output_port().Eval(scene_graph_context)\n",
    "\n",
    "        # Check collisions between the gripper and the sink\n",
    "        if query_object.HasCollisions():\n",
    "            cost = np.inf\n",
    "            return cost\n",
    "\n",
    "        # Check collisions between the gripper and the point cloud. `margin`` must\n",
    "        # be smaller than the margin used in the point cloud preprocessing.\n",
    "        margin = 0.0\n",
    "        for i in range(cloud.size()):\n",
    "            distances = query_object.ComputeSignedDistanceToPoint(cloud.xyz(i),\n",
    "                                                                  threshold=margin)\n",
    "            if distances:\n",
    "                cost = np.inf\n",
    "                return cost\n",
    "\n",
    "        n_GC = X_GW.rotation().multiply(cloud.normals()[:, indices])\n",
    "\n",
    "        # Reward sum |dot product of normals with gripper x|^2\n",
    "        cost = -np.sum(n_GC[0, :]**2)\n",
    "        return cost\n",
    "        \n",
    "    def GenerateAntipodalGraspCandidate(self, diagram, context, cloud, rng, wsg_body_index=None,\n",
    "                                    plant_system_name=\"plant\", scene_graph_system_name=\"scene_graph\"):\n",
    "        \"\"\"\n",
    "        Picks a random point in the cloud, and aligns the robot finger with the\n",
    "        x/y projection of the normal of that pixel. Perturbs z a little to find better grasps.\n",
    "        \"\"\"\n",
    "        plant = diagram.GetSubsystemByName(plant_system_name)\n",
    "        plant_context = plant.GetMyMutableContextFromRoot(context)\n",
    "        scene_graph = diagram.GetSubsystemByName(scene_graph_system_name)\n",
    "        scene_graph_context = scene_graph.GetMyMutableContextFromRoot(context)\n",
    "        if wsg_body_index:\n",
    "            wsg = plant.get_body(wsg_body_index)\n",
    "        else:\n",
    "            wsg = plant.GetBodyByName(\"body\")\n",
    "            wsg_body_index = wsg.index()\n",
    "\n",
    "        if cloud.size() < 1:\n",
    "            return np.inf, None\n",
    "\n",
    "        index = rng.integers(0, cloud.size() - 1)\n",
    "\n",
    "        # Use S for sample point/frame.\n",
    "        p_WS = cloud.xyz(index)\n",
    "        n_WS = cloud.normal(index)\n",
    "\n",
    "        assert np.isclose(np.linalg.norm(n_WS),\n",
    "                          1.0), f\"Normal has magnitude: {np.linalg.norm(n_WS)}\"\n",
    "\n",
    "        # Modification: always keep gripper y aligned with world -z\n",
    "        Gx = np.array([n_WS[0], n_WS[1], 0]) # Project onto XY plane\n",
    "        Gx = Gx / np.linalg.norm(Gx)\n",
    "        Gy = np.array([0.0, 0.0, -1.0]) # World downward\n",
    "        Gz = np.cross(Gx, Gy)\n",
    "        R_WG = RotationMatrix(np.vstack((Gx, Gy, Gz)).T)\n",
    "        p_GS_G = [0.054 - 0.01, 0.1, 0] # Position of sample end wrt gripper\n",
    "        p_WG = p_WS - R_WG @ p_GS_G\n",
    "\n",
    "        # Try vertical perturbations\n",
    "        min_z = -0.02\n",
    "        max_z = 0.02\n",
    "        for z in np.linspace(min_z, max_z, num=5):\n",
    "            p_WG_2 = p_WG + np.array([0, 0, z])\n",
    "            X_G = RigidTransform(R_WG, p_WG_2)\n",
    "            plant.SetFreeBodyPose(plant_context, wsg, X_G)\n",
    "            cost = self.GraspCandidateCost(diagram, context, cloud, adjust_X_G=True)\n",
    "            X_G = plant.GetFreeBodyPose(plant_context, wsg)\n",
    "            if np.isfinite(cost):\n",
    "                return cost, X_G\n",
    "\n",
    "        return np.inf, None\n",
    "        \n",
    "    def SelectGrasp(self, context, output):\n",
    "        \n",
    "        score, item_selection, down_sampled_pcd = self.GetInputPort(\"point_cloud_W\").Eval(context)\n",
    "        if score < 0.75:\n",
    "            output.set_value((np.inf, self.X_WHome, item_selection))\n",
    "            return\n",
    "\n",
    "        costs = []\n",
    "        X_Gs = []\n",
    "        for i in range(25):\n",
    "            cost, X_G = self.GenerateAntipodalGraspCandidate(\n",
    "                self._internal_model, self._internal_model_context,\n",
    "                down_sampled_pcd, self._rng)\n",
    "            if np.isfinite(cost):\n",
    "                costs.append(cost)\n",
    "                X_Gs.append(X_G)\n",
    "\n",
    "        if len(costs) == 0:\n",
    "            # Didn't find a viable grasp candidate\n",
    "            output.set_value((np.inf, self.X_WHome))\n",
    "        else:\n",
    "            best = np.argmin(costs)\n",
    "            output.set_value((costs[best], X_Gs[best], item_selection))\n",
    "            \n",
    "\n",
    "class PlannerState(Enum):\n",
    "    DEBUG = -1\n",
    "    WAIT = 0\n",
    "    SELECT_GRASP = 1\n",
    "    PICK = 2\n",
    "    PLACE = 3\n",
    "    HOME = 4\n",
    "    CLOSE = 5\n",
    "    OPEN = 6\n",
    "            \n",
    "            \n",
    "class Planner(LeafSystem):\n",
    "    def __init__(self, plant):\n",
    "        LeafSystem.__init__(self)\n",
    "        \n",
    "        self._gripper_body_index = plant.GetBodyByName(\"body\").index()\n",
    "        self.DeclareAbstractInputPort(\"body_poses\", AbstractValue.Make([RigidTransform()]))\n",
    "        self._grasp_index = self.DeclareAbstractInputPort(\"grasp_selection\", \n",
    "            AbstractValue.Make((np.inf, RigidTransform(), ITEM_NAMES[0]))).get_index()\n",
    "        self._wsg_state_index = self.DeclareVectorInputPort(\"wsg_state\", 2).get_index()\n",
    "        self.DeclareVectorInputPort(\"iiwa_position\", 7)\n",
    "        \n",
    "        self.X_WHome = X_WHome\n",
    "        self.X_WRecycle = RigidTransform(\n",
    "            RotationMatrix([\n",
    "                [0, 0, -1],\n",
    "                [1, 0, 0],\n",
    "                [0, -1, 0]\n",
    "            ]),\n",
    "            [0.4, -0.25, 0.65])\n",
    "        self.X_WTrash = RigidTransform(\n",
    "            RotationMatrix([\n",
    "                [0, 0, -1],\n",
    "                [1, 0, 0],\n",
    "                [0, -1, 0]\n",
    "            ]),\n",
    "            [0.4, -.1, 0.65])\n",
    "        self.X_WOrganic = RigidTransform(\n",
    "            RotationMatrix([\n",
    "                [0, 0, -1],\n",
    "                [1, 0, 0],\n",
    "                [0, -1, 0]\n",
    "            ]),\n",
    "            [0.4, 0.05, 0.65])\n",
    "        \n",
    "        self.eps = 1e-4\n",
    "        self.init = True\n",
    "        self.prev_time = None\n",
    "        self.mode = PlannerState.WAIT\n",
    "        self.wsg_des = np.array([0.107])\n",
    "        self.traj_WG = PiecewisePose.MakeLinear([0, np.inf], [RigidTransform(), RigidTransform()])\n",
    "        self.garbage_type = GarbageType.RECYCLE\n",
    "        \n",
    "        self.DeclareVectorOutputPort(\"wsg_position\", 1,\n",
    "            lambda context, output: output.SetFromVector([self.wsg_des]))\n",
    "        self.DeclareVectorOutputPort(\"V_WG\", 6, self.SendTrajV)\n",
    "        \n",
    "        self.DeclarePeriodicUnrestrictedUpdateEvent(0.1, 0.0, self.Update)\n",
    "        \n",
    "    def Update(self, context, state):\n",
    "        if self.mode == PlannerState.DEBUG:\n",
    "            return\n",
    "        \n",
    "        if self.init:\n",
    "            self.prev_time = context.get_time()\n",
    "            self.init = False\n",
    "            return\n",
    "        \n",
    "        if self.mode == PlannerState.WAIT:\n",
    "            if context.get_time() - self.prev_time > 2.:\n",
    "                self.mode = PlannerState.SELECT_GRASP\n",
    "            \n",
    "        if self.mode == PlannerState.SELECT_GRASP:\n",
    "            print(\"Selecting grasp\")\n",
    "            [cost, X_WD, item_selection] = self.get_input_port(self._grasp_index).Eval(context)\n",
    "            self.garbage_type = get_garbage_type[item_selection]\n",
    "            print(\"Cost: \", cost, \"\\n\", \"TF: \", X_WD)\n",
    "            if cost == np.inf:\n",
    "                self.mode = PlannerState.WAIT\n",
    "                self.prev_time = context.get_time()\n",
    "            else:\n",
    "                self.traj_WG = self.MakePickingTraj(context, X_WD)\n",
    "                self.mode = PlannerState.PICK\n",
    "                \n",
    "        if self.mode == PlannerState.PICK:\n",
    "            if self.TrajDone(context):\n",
    "                self.mode = PlannerState.CLOSE\n",
    "                self.wsg_des = np.array([0.0])\n",
    "            # Handle error cases\n",
    "            \n",
    "        # Need a better way to determine when it's closed.\n",
    "        if self.mode == PlannerState.CLOSE:\n",
    "            if context.get_time() - self.prev_time > 2.:\n",
    "                self.traj_WG = self.MakePlacingTraj(context, self.garbage_type)\n",
    "                self.mode = PlannerState.PLACE\n",
    "#             wsg_state = self.get_input_port(self._wsg_state_index).Eval(context)\n",
    "#             if wsg_state[0] < 0.01:\n",
    "            \n",
    "        if self.mode == PlannerState.PLACE:\n",
    "            if self.TrajDone(context):\n",
    "                self.mode = PlannerState.OPEN\n",
    "                self.wsg_des = np.array([0.107])\n",
    "            # Handle error cases\n",
    "            \n",
    "        if self.mode == PlannerState.OPEN:\n",
    "            wsg_state = self.get_input_port(self._wsg_state_index).Eval(context)\n",
    "            if wsg_state[0] > 0.09:\n",
    "                self.traj_WG = self.MakeHomeTraj(context)\n",
    "                self.mode = PlannerState.HOME\n",
    "                \n",
    "        if self.mode == PlannerState.HOME:\n",
    "            if self.TrajDone(context):\n",
    "                self.mode = PlannerState.SELECT_GRASP\n",
    "            \n",
    "\n",
    "    def TrajDone(self, context):\n",
    "        \"\"\"\n",
    "        Checks if we have completed our desired trajectory\n",
    "            - Time elapsed\n",
    "            - We're at the desired end pose\n",
    "        If time is up and we're no longer moving, but we haven't \n",
    "            gone to our desired location, then make a micro-adjustment.\n",
    "        \"\"\"\n",
    "        time = context.get_time()\n",
    "        X_WG = self.get_input_port(0).Eval(context)[int(self._gripper_body_index)]\n",
    "        X_WEnd = self.traj_WG.GetPose(np.inf)\n",
    "        if X_WG.IsNearlyEqualTo(X_WEnd, self.eps):\n",
    "            return True\n",
    "        elif self.traj_WG.end_time() < time:\n",
    "            self.traj_WG = PiecewisePose.MakeLinear([time, time+0.25], [X_WG, X_WEnd])\n",
    "        \n",
    "        return False\n",
    "\n",
    "    def MakePickingTraj(self, context, X_WD):\n",
    "        \"\"\"\n",
    "        Creates a basic picking trajectory\n",
    "        \"\"\"\n",
    "        time = context.get_time()\n",
    "        X_WG = self.get_input_port(0).Eval(context)[int(self._gripper_body_index)]\n",
    "        X_WPrepick = RigidTransform(RotationMatrix(), [0, 0, 0.1]) @ X_WD\n",
    "        traj_WG = PiecewisePose.MakeLinear([time, time+2, time+4], [X_WG, X_WPrepick, X_WD])\n",
    "        \n",
    "        return traj_WG\n",
    "    \n",
    "    def MakePlacingTraj(self, context, garbage_type):\n",
    "        \"\"\"\n",
    "        Creates a placing trajectory to either trash, recycle, or organic bin\n",
    "        \"\"\"\n",
    "        time = context.get_time()\n",
    "        X_WG = self.get_input_port(0).Eval(context)[int(self._gripper_body_index)]\n",
    "        if garbage_type == GarbageType.TRASH:\n",
    "            traj_WG = PiecewisePose.MakeLinear([time, time+2, time+6], [X_WG, self.X_WHome, self.X_WTrash])\n",
    "        elif garbage_type == GarbageType.RECYCLE:\n",
    "            traj_WG = PiecewisePose.MakeLinear([time, time+2, time+6], [X_WG, self.X_WHome, self.X_WRecycle])\n",
    "        elif garbage_type == GarbageType.ORGANIC:\n",
    "            traj_WG = PiecewisePose.MakeLinear([time, time+2, time+6], [X_WG, self.X_WHome, self.X_WOrganic])\n",
    "            \n",
    "        return traj_WG\n",
    "    \n",
    "    def MakeHomeTraj(self, context):\n",
    "        \"\"\"\n",
    "        Creates a basic trajectory for going to home position\n",
    "        \"\"\"\n",
    "        time = context.get_time()\n",
    "        X_WG = self.get_input_port(0).Eval(context)[int(self._gripper_body_index)]\n",
    "        traj_WG = PiecewisePose.MakeLinear([time, time+4], [X_WG, self.X_WHome])\n",
    "        \n",
    "        return traj_WG\n",
    "\n",
    "    def SendTrajV(self, context, output):\n",
    "        \"\"\"\n",
    "        Callback for evaluating V_WG. Makes derivative of trajectory and publishes\n",
    "        the V_WG corresponding to current time.\n",
    "        \"\"\"\n",
    "        time = context.get_time()\n",
    "        V_WG = self.traj_WG.GetVelocity(time)\n",
    "        output.SetFromVector(V_WG)\n",
    "\n",
    "        \n",
    "class IIWA(LeafSystem):\n",
    "    def __init__(self):\n",
    "        LeafSystem.__init__(self)\n",
    "            \n",
    "        # Setup diagram builder components\n",
    "        builder = DiagramBuilder()\n",
    "        self.station = MakeManipulationStation(\n",
    "            filename=FindResource(MODEL_YAML),\n",
    "            package_xmls=[\"./package.xml\"])\n",
    "        builder.AddSystem(self.station)\n",
    "        self.plant = self.station.GetSubsystemByName(\"plant\")\n",
    "        self.visualizer = MeshcatVisualizer.AddToBuilder(\n",
    "            builder, self.station.GetOutputPort(\"query_object\"), meshcat)  \n",
    "#         self.collision = MeshcatVisualizer.AddToBuilder(\n",
    "#             builder, self.station.GetOutputPort(\"query_object\"), meshcat,\n",
    "#             MeshcatVisualizerParams(role=Role.kProximity, prefix=\"collision\"))\n",
    "\n",
    "        # Add vision system\n",
    "        vision = builder.AddNamedSystem(\"vision\", \n",
    "            Vision(self.station,\n",
    "                   camera_body_indices=[\n",
    "                      self.plant.GetBodyIndices(\n",
    "                          self.plant.GetModelInstanceByName(\"camera0\"))[0],\n",
    "                      self.plant.GetBodyIndices(\n",
    "                          self.plant.GetModelInstanceByName(\"camera1\"))[0]\n",
    "                  ]))\n",
    "        builder.Connect(self.station.GetOutputPort(\"camera0_depth_image\"),\n",
    "                        vision.get_input_port(0))\n",
    "        builder.Connect(self.station.GetOutputPort(\"camera1_depth_image\"),\n",
    "                        vision.get_input_port(1))\n",
    "        builder.Connect(self.station.GetOutputPort(\"camera0_rgb_image\"),\n",
    "                        vision.get_input_port(2))\n",
    "        builder.Connect(self.station.GetOutputPort(\"camera1_rgb_image\"),\n",
    "                        vision.get_input_port(3))\n",
    "        builder.Connect(self.station.GetOutputPort(\"body_poses\"),\n",
    "                        vision.GetInputPort(\"body_poses\"))\n",
    "        \n",
    "        # Add grasp selector\n",
    "        grasp_selector = builder.AddNamedSystem(\"grasp_selector\", GraspSelector())\n",
    "        builder.Connect(vision.GetOutputPort(\"point_cloud_W\"),\n",
    "            grasp_selector.GetInputPort(\"point_cloud_W\"))\n",
    "        \n",
    "        # Planner\n",
    "        planner = builder.AddNamedSystem(\"planner\", Planner(self.plant))\n",
    "        builder.Connect(self.station.GetOutputPort(\"body_poses\"),\n",
    "                    planner.GetInputPort(\"body_poses\"))\n",
    "        builder.Connect(grasp_selector.GetOutputPort(\"grasp_selection\"),\n",
    "                        planner.GetInputPort(\"grasp_selection\"))\n",
    "        builder.Connect(self.station.GetOutputPort(\"wsg_state_measured\"),\n",
    "                        planner.GetInputPort(\"wsg_state\"))\n",
    "        builder.Connect(self.station.GetOutputPort(\"iiwa_position_measured\"),\n",
    "                        planner.GetInputPort(\"iiwa_position\"))\n",
    "        \n",
    "        # Add pseudo-inverse controller\n",
    "        self.controller = builder.AddSystem(PseudoInverseController(self.plant))\n",
    "        self.controller.set_name(\"PseudoInverseController\")\n",
    "        builder.Connect(planner.GetOutputPort(\"V_WG\"), self.controller.GetInputPort(\"V_WG\"))\n",
    "        # Integrate controller velocity commands to get joint angles\n",
    "        self.integrator = builder.AddSystem(Integrator(7))\n",
    "        self.integrator.set_name(\"integrator\")\n",
    "        builder.Connect(self.controller.get_output_port(),\n",
    "                        self.integrator.get_input_port())\n",
    "        builder.Connect(self.integrator.get_output_port(),\n",
    "                        self.station.GetInputPort(\"iiwa_position\"))\n",
    "        builder.Connect(self.station.GetOutputPort(\"iiwa_position_measured\"),\n",
    "                        self.controller.GetInputPort(\"iiwa_position\"))\n",
    "        \n",
    "        # Gripper control\n",
    "        builder.Connect(planner.GetOutputPort(\"wsg_position\"),\n",
    "                    self.station.GetInputPort(\"wsg_position\"))\n",
    "        \n",
    "        # Finalize\n",
    "        self.diagram = builder.Build()\n",
    "        self.context = self.diagram.CreateDefaultContext()\n",
    "        \n",
    "        # Set current position\n",
    "        self.integrator.set_integral_value(\n",
    "            self.integrator.GetMyMutableContextFromRoot(self.context), q0)\n",
    "            \n",
    "        # Randomize poses of trash\n",
    "        self._trash_model = make_trash_model()\n",
    "        self.RandomizeTrash()\n",
    "        \n",
    "        # Publish context\n",
    "        self.diagram.Publish(self.context)\n",
    "        \n",
    "    def RandomizeTrash(self):\n",
    "        \n",
    "        trash_context = self._trash_model.CreateDefaultContext()\n",
    "        trash_plant = self._trash_model.GetSubsystemByName(\"plant\")\n",
    "        trash_plant_context = trash_plant.GetMyMutableContextFromRoot(trash_context)\n",
    "        trash_scene_graph = self._trash_model.GetSubsystemByName(\"scene_graph\")\n",
    "        trash_scene_graph_context = trash_scene_graph.GetMyMutableContextFromRoot(trash_context)\n",
    "        query_object = trash_scene_graph.get_query_output_port().Eval(trash_scene_graph_context)\n",
    "        \n",
    "        iterate = True\n",
    "        counter = 0\n",
    "        body_tfs = {}\n",
    "        while iterate:\n",
    "            for body_index in trash_plant.GetFloatingBaseBodies():\n",
    "                body = trash_plant.get_body(body_index)\n",
    "                if body.name() in ITEM_NAMES:\n",
    "                    tf = RigidTransform(\n",
    "                            UniformlyRandomRotationMatrix(generator),\n",
    "                            [0.75*np.random.rand() - 0.375, 0.16*np.random.rand() - 0.08 -.6, .44])\n",
    "                    trash_plant.SetFreeBodyPose(trash_plant_context, body, tf)\n",
    "                    body_tfs[body.name()] = tf\n",
    "                    \n",
    "            iterate = query_object.HasCollisions()\n",
    "            counter += 1\n",
    "            if counter > 40:\n",
    "                print(\"Large amount of consecutive failures, stopping...\")\n",
    "                break\n",
    "        \n",
    "        plant_context = self.plant.GetMyMutableContextFromRoot(self.context)\n",
    "        if not query_object.HasCollisions():\n",
    "            print(f\"Objects randomized successfully after {counter} tries\")\n",
    "            for body_index in self.plant.GetFloatingBaseBodies():\n",
    "                body = self.plant.get_body(body_index)\n",
    "                if body.name() in ITEM_NAMES:\n",
    "                    self.plant.SetFreeBodyPose(plant_context, body, body_tfs[body.name()])\n",
    "        \n",
    "    def Simulate(self, t):\n",
    "        \n",
    "        # Simulator\n",
    "        simulator = Simulator(self.diagram, self.context)\n",
    "        simulator.set_target_realtime_rate(1.0)\n",
    "        self.visualizer.StartRecording()\n",
    "        simulator.AdvanceTo(t)\n",
    "        self.visualizer.PublishRecording()\n",
    "        \n",
    "    def GetIms(self):\n",
    "        \n",
    "        station_context = self.diagram.GetMutableSubsystemContext(self.station, self.context)\n",
    "        im0 = self.station.GetOutputPort(\"camera0_rgb_image\").Eval(station_context).data\n",
    "        im1 = self.station.GetOutputPort(\"camera1_rgb_image\").Eval(station_context).data\n",
    "        \n",
    "        return [im0, im1]\n",
    "    \n",
    "    def GetLabelIms(self):\n",
    "        # Still need to do .squeeze() on each image output to view in matplotlib\n",
    "        station_context = self.diagram.GetMutableSubsystemContext(self.station, self.context)\n",
    "        im0 = self.station.GetOutputPort(\"camera0_label_image\").Eval(station_context).data\n",
    "        im1 = self.station.GetOutputPort(\"camera1_label_image\").Eval(station_context).data\n",
    "        \n",
    "        return [im0, im1]\n",
    "    \n",
    " \n",
    "meshcat.Delete()\n",
    "iiwa = IIWA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting grasp\n",
      "{1: 1.960726261138916, 2: 1.8075592517852783, 3: 1.9633259773254395, 4: 1.9030123949050903}\n",
      "Decided to pick up  Orange\n",
      "Cost:  -20.021505017616207 \n",
      " TF:  RigidTransform(\n",
      "  R=RotationMatrix([\n",
      "    [-0.6884053149133325, 0.0, 0.725326217917894],\n",
      "    [-0.725326217917894, -2.220446049250313e-16, -0.6884053149133322],\n",
      "    [0.0, -1.0000000000000002, -2.220446049250313e-16],\n",
      "  ]),\n",
      "  p=[-0.048446556476337416, -0.6231942325865776, 0.5024986624717712],\n",
      ")\n",
      "Selecting grasp\n",
      "{1: 1.959364891052246, 2: 1.8260812759399414, 3: 0.12109408527612686, 4: 1.9210864305496216}\n",
      "Decided to pick up  bottle\n",
      "Cost:  -17.872753851489573 \n",
      " TF:  RigidTransform(\n",
      "  R=RotationMatrix([\n",
      "    [-0.7230504175540644, 0.0, 0.6907952617634932],\n",
      "    [-0.6907952617634932, 0.0, -0.7230504175540644],\n",
      "    [0.0, -1.0, 0.0],\n",
      "  ]),\n",
      "  p=[-0.3007609178526606, -0.6018996455035304, 0.515854285955429],\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "iiwa.Simulate(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
